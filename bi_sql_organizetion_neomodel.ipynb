{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sean.chang\\AppData\\Local\\anaconda3\\envs\\bibot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils import read_config, OracleAgent, MySQLAgent\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "from py2neo import Graph, Node, Relationship\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "from langchain.chat_models  import AzureChatOpenAI\n",
    "\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import (\n",
    "    ChatGoogleGenerativeAI,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "\n",
    "import prompts\n",
    "import ast\n",
    "\n",
    "\n",
    "from models.neo4jmodels import config, db, BaseTable, JoinTable, AggregatTable, UnionTable, View\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.DATABASE_URL = \"neo4j://neo4j:yfy12345@138.3.214.21:7687\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data has been deleted from the Neo4j database.\n"
     ]
    }
   ],
   "source": [
    "def clear_all_nodes(db):\n",
    "    delete_query = \"MATCH (n) DETACH DELETE n\"\n",
    "\n",
    "    db.cypher_query(delete_query)\n",
    "\n",
    "    print(\"All data has been deleted from the Neo4j database.\")\n",
    "clear_all_nodes(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check current nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_all_nodes(db):\n",
    "    query = \"\"\"\n",
    "    MATCH (a)-[r:FROM]->(b)\n",
    "    RETURN a, r, b\n",
    "    \"\"\"\n",
    "\n",
    "    cypher_results, meta = db.cypher_query(query)\n",
    "    if cypher_results:\n",
    "        results_as_dict = [dict(zip(meta, row)) for row in cypher_results]\n",
    "        return results_as_dict\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "results_as_dict = check_all_nodes(db)\n",
    "results_as_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>view_name</th>\n",
       "      <th>text</th>\n",
       "      <th>input</th>\n",
       "      <th>lineage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C$_0W_YFY_AV_TW_R</td>\n",
       "      <td>select \"C1_ROW_ID\",\"C2_ORG_ID\",\"C3_REF_AV_HEAD...</td>\n",
       "      <td>select \"C1_ROW_ID\",\"C2_ORG_ID\",\"C3_REF_AV_HEAD...</td>\n",
       "      <td>Result = {\\n\"Union1\": \"\\nDatasource = ['W_YFY_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C$_0W_YFY_IND_FIN_INFO_FS</td>\n",
       "      <td>select   FIN_INFO.SEQ    C1_SEQ,  FIN_INFO.ACC...</td>\n",
       "      <td>select   FIN_INFO.SEQ    C1_SEQ,  FIN_INFO.ACC...</td>\n",
       "      <td>Result = {\\n\"Query\" : \"\\nDatasource = ['ODS.TC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OP_FACT_CHP_INVENTORY_ETH_PULP</td>\n",
       "      <td>SELECT PERIOD_NAME,STOCK_DATE TDATE,ORG_CODE,'...</td>\n",
       "      <td>SELECT PERIOD_NAME,STOCK_DATE TDATE,ORG_CODE,'...</td>\n",
       "      <td>Result = {\\n\"Union1\":\"\\n    Datasource=['W_FAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OP_FACT_CHP_INVENTORY_REDEFINE</td>\n",
       "      <td>SELECT PERIOD_NAME,TDATE,ORG_CODE   ,CASE ORG_...</td>\n",
       "      <td>SELECT PERIOD_NAME,TDATE,ORG_CODE   ,CASE ORG_...</td>\n",
       "      <td>Result = {\\n\"Union1\" : \"\\nDatasource = ['W_YFY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W_OSH_TARGET_NEW_V</td>\n",
       "      <td>select \"PERIOD_YEAR\",\"DATA_LEVEL\",\"COUNTRY_ID\"...</td>\n",
       "      <td>select \"PERIOD_YEAR\",\"DATA_LEVEL\",\"COUNTRY_ID\"...</td>\n",
       "      <td>Result = {\\n\"Union1\" : \"\\nDatasource = ['w_osh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        view_name  \\\n",
       "0               C$_0W_YFY_AV_TW_R   \n",
       "1       C$_0W_YFY_IND_FIN_INFO_FS   \n",
       "2  OP_FACT_CHP_INVENTORY_ETH_PULP   \n",
       "3  OP_FACT_CHP_INVENTORY_REDEFINE   \n",
       "4              W_OSH_TARGET_NEW_V   \n",
       "\n",
       "                                                text  \\\n",
       "0  select \"C1_ROW_ID\",\"C2_ORG_ID\",\"C3_REF_AV_HEAD...   \n",
       "1  select   FIN_INFO.SEQ    C1_SEQ,  FIN_INFO.ACC...   \n",
       "2  SELECT PERIOD_NAME,STOCK_DATE TDATE,ORG_CODE,'...   \n",
       "3  SELECT PERIOD_NAME,TDATE,ORG_CODE   ,CASE ORG_...   \n",
       "4  select \"PERIOD_YEAR\",\"DATA_LEVEL\",\"COUNTRY_ID\"...   \n",
       "\n",
       "                                               input  \\\n",
       "0  select \"C1_ROW_ID\",\"C2_ORG_ID\",\"C3_REF_AV_HEAD...   \n",
       "1  select   FIN_INFO.SEQ    C1_SEQ,  FIN_INFO.ACC...   \n",
       "2  SELECT PERIOD_NAME,STOCK_DATE TDATE,ORG_CODE,'...   \n",
       "3  SELECT PERIOD_NAME,TDATE,ORG_CODE   ,CASE ORG_...   \n",
       "4  select \"PERIOD_YEAR\",\"DATA_LEVEL\",\"COUNTRY_ID\"...   \n",
       "\n",
       "                                             lineage  \n",
       "0  Result = {\\n\"Union1\": \"\\nDatasource = ['W_YFY_...  \n",
       "1  Result = {\\n\"Query\" : \"\\nDatasource = ['ODS.TC...  \n",
       "2  Result = {\\n\"Union1\":\"\\n    Datasource=['W_FAC...  \n",
       "3  Result = {\\n\"Union1\" : \"\\nDatasource = ['W_YFY...  \n",
       "4  Result = {\\n\"Union1\" : \"\\nDatasource = ['w_osh...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidb_view = pd.read_csv('./result/nice_result_1.csv')\n",
    "bidb_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old extraction function\n",
    "def extract_lists(input_string):\n",
    "    # Initialize dictionary to hold the lists\n",
    "    extracted_data = {}\n",
    "    \n",
    "    # Use regex to find the Datasource part\n",
    "    datasource_match = re.search(r\"Datasource\\s*=\\s*(\\[.*?\\])\", input_string, re.DOTALL)\n",
    "    if datasource_match:\n",
    "        datasource_section = datasource_match.group(1).strip()\n",
    "        extracted_data[\"Datasource\"] = ast.literal_eval(datasource_section)\n",
    "    \n",
    "    # Use regex to find the Relationship part\n",
    "    relationship_match = re.search(r\"Relationship\\s*=\\s*(\\[.*?\\])\", input_string, re.DOTALL)\n",
    "    if relationship_match:\n",
    "        relationship_section = relationship_match.group(1).strip()\n",
    "        # Split the relationship section into individual items\n",
    "        relationship_list = re.findall(r'\\((.*?)\\)', relationship_section, re.DOTALL)\n",
    "        \n",
    "        # Process each item in the relationship list\n",
    "        processed_list = []\n",
    "        for item in relationship_list:\n",
    "            # Replace any variation of \"FILTER\" with \"Filter\"\n",
    "            item = re.sub(r'^FILTER\\s*:?', 'Filter:', item, flags=re.IGNORECASE)\n",
    "            # Remove any newline characters and extra spaces\n",
    "            item = re.sub(r'\\s+', ' ', item.strip())\n",
    "            processed_list.append(item)\n",
    "        \n",
    "        extracted_data[\"Relationship\"] = processed_list\n",
    "\n",
    "    return extracted_data[\"Datasource\"], extracted_data[\"Relationship\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_destructure(input_string):\n",
    "\n",
    "    \"\"\"\n",
    "    1. Separate each Union as one dictionary\n",
    "    2. Extract Filter and Join as list, Groupby as dictionary \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_result_string(result_string):\n",
    "    \"\"\"\n",
    "    Parses the given result string and structures it into a dictionary.\n",
    "    \"\"\"\n",
    "    # Initialize the main dictionary\n",
    "    result_dict = {}\n",
    "\n",
    "    # Clean up the input string\n",
    "    cleaned_string = result_string.strip().replace('\\n', '').replace('\\t', '').replace('\\r', '')\n",
    "\n",
    "    # Split the string into different Unions and Final\n",
    "    pattern = r'\"(Union\\d+|Final)\"\\s*:\\s*\"([^\"]*)\"'\n",
    "    matches = re.findall(pattern, cleaned_string)\n",
    "\n",
    "    if not matches:\n",
    "        # Handle Union3 which seems to have a different format\n",
    "        pattern = r'\"(Union\\d+|Final)\":\\s*\"([^\"]*)\"'\n",
    "        matches = re.findall(pattern, cleaned_string)\n",
    "\n",
    "    for match in matches:\n",
    "        union_name = match[0]\n",
    "        union_content = match[1]\n",
    "\n",
    "        # Initialize the union dictionary\n",
    "        union_dict = {}\n",
    "\n",
    "        # Extract Datasource\n",
    "        datasource_pattern = r'Datasource\\s*=\\s*(\\[[^\\]]*\\])'\n",
    "        datasource_match = re.search(datasource_pattern, union_content)\n",
    "        if datasource_match:\n",
    "            datasource_str = datasource_match.group(1)\n",
    "            try:\n",
    "                datasource_list = ast.literal_eval(datasource_str)\n",
    "            except Exception:\n",
    "                datasource_list = []\n",
    "        else:\n",
    "            datasource_list = []\n",
    "        union_dict['Datasource'] = datasource_list\n",
    "\n",
    "        # Extract Filter\n",
    "        filter_pattern = r'Filter\\s*=\\s*(\\[[^\\]]*\\])'\n",
    "        filter_match = re.search(filter_pattern, union_content)\n",
    "        if filter_match:\n",
    "            filter_str = filter_match.group(1)\n",
    "            try:\n",
    "                filter_list = ast.literal_eval(filter_str)\n",
    "            except Exception:\n",
    "                filter_list = []\n",
    "        else:\n",
    "            filter_list = []\n",
    "        union_dict['Filter'] = filter_list\n",
    "\n",
    "        # Extract Join\n",
    "        join_pattern = r'Join\\s*=\\s*(\\[[^\\]]*\\])'\n",
    "        join_match = re.search(join_pattern, union_content)\n",
    "        if join_match:\n",
    "            join_str = join_match.group(1)\n",
    "            try:\n",
    "                join_list = ast.literal_eval(join_str)\n",
    "            except Exception:\n",
    "                join_list = []\n",
    "        else:\n",
    "            join_list = []\n",
    "        union_dict['Join'] = join_list\n",
    "\n",
    "        # Extract Groupby\n",
    "        groupby_pattern = r'Groupby\\s*=\\s*(\\{[^\\}]*\\}|\\[[^\\]]*\\]|\\\"[^\\\"]*\\\")'\n",
    "        groupby_match = re.search(groupby_pattern, union_content)\n",
    "        if groupby_match:\n",
    "            groupby_str = groupby_match.group(1)\n",
    "            # Determine if it's a dictionary or list\n",
    "            if groupby_str.startswith('{') and groupby_str.endswith('}'):\n",
    "                try:\n",
    "                    groupby_dict = ast.literal_eval(groupby_str)\n",
    "                except Exception:\n",
    "                    groupby_dict = {}\n",
    "            elif groupby_str.startswith('[') and groupby_str.endswith(']'):\n",
    "                try:\n",
    "                    groupby_list = ast.literal_eval(groupby_str)\n",
    "                    groupby_dict = {i: None for i in groupby_list}\n",
    "                except Exception:\n",
    "                    groupby_dict = {}\n",
    "            else:\n",
    "                groupby_dict = {}\n",
    "        else:\n",
    "            groupby_dict = {}\n",
    "        union_dict['Groupby'] = groupby_dict\n",
    "\n",
    "        # Add the union dictionary to the main result dictionary\n",
    "        result_dict[union_name] = union_dict\n",
    "\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Union1': {'Datasource': ['W_YFY_INV_BALANCE_F',\n",
       "   'w_chp_item_d',\n",
       "   'W_YFY_ORG_D',\n",
       "   'W_CHP_TS_BELONG_ORG_R'],\n",
       "  'Filter': [],\n",
       "  'Join': [],\n",
       "  'Groupby': {}},\n",
       " 'Union2': {'Datasource': ['W_YFY_INV_BALANCE_F',\n",
       "   'w_chp_item_d',\n",
       "   'W_YFY_ORG_D',\n",
       "   'W_CHP_TS_BELONG_ORG_R'],\n",
       "  'Filter': [],\n",
       "  'Join': [],\n",
       "  'Groupby': {}},\n",
       " 'Final': {'Datasource': ['(All Union Tables)'],\n",
       "  'Filter': [],\n",
       "  'Join': [],\n",
       "  'Groupby': {}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_result_string(bidb_view.iloc[3].lineage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_lineage = {}\n",
    "for idx, row in bidb_view.iterrows():\n",
    "\n",
    "    datasource_list, relationship_list = extract_lists(row.lineage)\n",
    "    \n",
    "    extracted_lineage[row.view_name] = {\n",
    "        'datasource': datasource_list,\n",
    "        'relationship': relationship_list\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OP_FACT_CHP_INVENTORY_ETH_PULP': {'datasource': ['W_FACTORY_INV_BALANCE_F',\n",
       "   'W_FACTORY_INV_F'],\n",
       "  'relationship': [\"Filter: W_FACTORY_INV_F.ORG_CODE = 'ETH'\",\n",
       "   \"Filter: W_FACTORY_INV_F.MEMO = '花蓮自製漿'\",\n",
       "   'JOIN: W_FACTORY_INV_F.STOCK_DATE = (SELECT max(stock_date',\n",
       "   \"CURRENT_DATE, 'yyyy/mm'\"]}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_key = list(extracted_lineage.keys())[2]\n",
    "test_value = extracted_lineage[test_key]\n",
    "\n",
    "\n",
    "test_dict = {test_key: test_value}\n",
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in test_dict.items():\n",
    "    table_list = item['datasource']\n",
    "    relationship = item['relationship']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Filter: W_CHP_ORDER_TYPE_D.USED = '損益'\",\n",
       " \"Filter: W_CHP_SALES_NOMANUAL_F.ORDER_LINE_STATUS = 'AWAITING_SHIPPING'\",\n",
       " 'Filter: GREATEST(W_CHP_SALES_NOMANUAL_F.REQUEST_DATE, W_CHP_SALES_NOMANUAL_F.SCHEDULE_SHIP_DATE',\n",
       " 'ADD_MONTHS(sysdate, -2',\n",
       " 'JOIN: W_CHP_SALES_NOMANUAL_F.order_type = W_CHP_ORDER_TYPE_D.order_type',\n",
       " 'JOIN: W_CHP_SALES_NOMANUAL_F.line_order_type = W_CHP_ORDER_TYPE_D.order_line_type',\n",
       " 'JOIN: W_CHP_SALES_NOMANUAL_F.PAPER_STAT_GROUP_SALES = W_CHP_PAPER_SALES_ORNT_R.PAPER_STAT_GROUP_SALES(+',\n",
       " 'JOIN: W_CHP_SALES_NOMANUAL_F.paper_stat_element = W_CHP_PAPER_STAT_GROUP_R.paper_stat_element(+',\n",
       " \"Filter: W_CHP_SALES_NOMANUAL_F.om_customer_no <> 'S0001'\",\n",
       " \"Filter: W_CHP_SALES_NOMANUAL_F.om_customer_no NOT LIKE 'Z%' OR W_CHP_SALES_NOMANUAL_F.om_customer_no = 'Z5170'\",\n",
       " 'JOIN: W_CHP_SALES_NOMANUAL_F.ORG_CODE = W_YFY_ORG_D.ORG_CODE',\n",
       " 'JOIN: W_CHP_SALES_NOMANUAL_F.PAPER_STAT_GROUP_SALES = (SELECT DISTINCT PAPER_STAT_GROUP_SALES FROM W_CHP_PAPER_STAT_GROUP_R',\n",
       " 'Filter: W_CHP_SALES_NOMANUAL_F.TRX_DATE IS NOT NULL']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table:W_FACTORY_INV_F, rel:Filter: W_FACTORY_INV_F.ORG_CODE = 'ETH'\n",
      "we here\n",
      "table:W_FACTORY_INV_F, rel:Filter: W_FACTORY_INV_F.MEMO = '花蓮自製漿'\n",
      "we here\n",
      "table:W_FACTORY_INV_F, rel:JOIN: W_FACTORY_INV_F.STOCK_DATE = SELECT maxstock_date\n"
     ]
    }
   ],
   "source": [
    "for key, item in test_dict.items():\n",
    "    view_name = key\n",
    "    table_list = item['datasource']\n",
    "    relationship = item['relationship']\n",
    "    relationship = [item.replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\") for item in relationship]\n",
    "\n",
    "    for table in table_list:\n",
    "        for rel in relationship:\n",
    "            if table in rel:\n",
    "                print(f\"table:{table}, rel:{rel}\")\n",
    "\n",
    "                view_node = View.nodes.get_or_create()(name=view_name)\n",
    "\n",
    "                table_node = BaseTable.nodes.get_or_create()(name=table)\n",
    "\n",
    "\n",
    "\n",
    "                if \"Filter\" in rel:\n",
    "                    # connect view to the table with the conditions\n",
    "                    view_node.parent.connect(table_node)\n",
    "\n",
    "                    table_node.filter = rel\n",
    "                    table_node.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Filter: W_FACTORY_INV_F.ORG_CODE = 'ETH'\",\n",
       " \"Filter: W_FACTORY_INV_F.MEMO = '花蓮自製漿'\",\n",
       " 'JOIN: W_FACTORY_INV_F.STOCK_DATE = SELECT maxstock_date',\n",
       " \"CURRENT_DATE 'yyyy/mm'\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<View: {'name': 'OP_FACT_CHP_INVENTORY_ETH_PULP', 'element_id_property': '4:1106eaef-578b-4e12-bf10-90067c3c032e:13'}>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "View.nodes.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Table: {'name': 'W_FACTORY_INV_F', 'filter': \"Filter: W_FACTORY_INV_F.MEMO = '花蓮自製漿'\", 'groupby': None, 'element_id_property': '4:1106eaef-578b-4e12-bf10-90067c3c032e:14'}>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table.nodes.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NodeClassAlreadyDefined",
     "evalue": "Class __main__.Person with labels Person already defined:\nTable --> <class '__main__.Table'>\nView --> <class '__main__.View'>\nPerson --> <class '__main__.Person'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNodeClassAlreadyDefined\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPerson\u001b[39;00m(StructuredNode):\n\u001b[0;32m      2\u001b[0m     names \u001b[38;5;241m=\u001b[39m ArrayProperty(StringProperty(), required\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m bob \u001b[38;5;241m=\u001b[39m Person(names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbob\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrob\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrobert\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32mc:\\Users\\sean.chang\\AppData\\Local\\anaconda3\\envs\\bibot\\lib\\site-packages\\neomodel\\sync_\\core.py:1300\u001b[0m, in \u001b[0;36mNodeMeta.__new__\u001b[1;34m(mcs, name, bases, namespace)\u001b[0m\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__label__ \u001b[38;5;241m=\u001b[39m namespace\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__label__\u001b[39m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__optional_labels__ \u001b[38;5;241m=\u001b[39m namespace\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__optional_labels__\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[1;32m-> 1300\u001b[0m     \u001b[43mbuild_class_registry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\sean.chang\\AppData\\Local\\anaconda3\\envs\\bibot\\lib\\site-packages\\neomodel\\sync_\\core.py:1322\u001b[0m, in \u001b[0;36mbuild_class_registry\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m   1320\u001b[0m         db\u001b[38;5;241m.\u001b[39m_NODE_CLASS_REGISTRY[label_set] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1322\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NodeClassAlreadyDefined(\n\u001b[0;32m   1323\u001b[0m             \u001b[38;5;28mcls\u001b[39m, db\u001b[38;5;241m.\u001b[39m_NODE_CLASS_REGISTRY, db\u001b[38;5;241m.\u001b[39m_DB_SPECIFIC_CLASS_REGISTRY\n\u001b[0;32m   1324\u001b[0m         )\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m database \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__target_databases__:\n",
      "\u001b[1;31mNodeClassAlreadyDefined\u001b[0m: Class __main__.Person with labels Person already defined:\nTable --> <class '__main__.Table'>\nView --> <class '__main__.View'>\nPerson --> <class '__main__.Person'>\n"
     ]
    }
   ],
   "source": [
    "class Person(StructuredNode):\n",
    "    names = ArrayProperty(StringProperty(), required=True)\n",
    "\n",
    "bob = Person(names=['bob', 'rob', 'robert']).save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
